---
title: "(WIP) [RecSys] 뉴럴넷 기반 추천시스템 서베이 페이퍼 리뷰"
categories:
  - Recommender Systems
tags:
  - Survey Paper
  - Recommender Systems
  - Deep Learning
---

### 뉴럴넷 기반 추천 시스템 서베이 페이퍼 리뷰


> A Survey on Neural Recommendation: From Collaborative Filtering to Information-rich Recommendation 논문에서 정리한 뉴럴넷 기반 추천시스템의 큰 흐름에 대해 알아봅니다.  

<center><img src="/assets/materials/recsys/neural_survey/roadmap.png" align="center" alt="drawing" width="500"/></center>   


<font size="2"><center> 논문에서 제시된 Taxonomy 개요 </center>  </font>   
<br>


>  **1. 본 논문에서는 크게 3가지 접근법으로 나눔: Collaborative Filtering, Contents Based, Temporal/Sequential**
>
>  **2. 자연어, 그래프 등 비정형 데이터를 다루는 신경망 모델의 접근법이 추천 분야에 활발히 적용/응용되고 있음**
>
>  **3. 각 방법론이 발달한 배경을 통해 실제 문제 상황에서 마주할 수 있는 다양한 형태의 데이터와 비즈니스 환경에 적합함 모델을 취사선택할 수 있음**

<br/>

----


<br/>

#### Contents

<br/>

1.	[들어가며](#intro)
2.  [Collaborative Filtering Models](#cf-models)
3.  [Contents Based Models](#cb-models)
4.  [Temporal / Sequential Models](#temp-seq-models)
5.  [결론](#outro)  

<br />

## 1. 들어가며  

### motivation
하루가 다르게 새로운 방법론이 등장하는 머신러닝 분야에 몸 담고 있는 엔지니어에게, 빠르게 변화하는 흐름을 그 때 그 때 따라잡아야한다는 부담감은 일종의 끝나지 않는 과제처럼 마음에 머무르고 있을 것입니다. 한동안 현업에 치여서 이러한 동향을 놓친듯 할 때 참고하면 좋을 것이 바로 survey paper인데요.  

[본 추천시스템 서베이 페이퍼](https://arxiv.org/abs/2104.13030)는 2021년 상반기에 공개된 페이퍼로, 강화학습이나 그래프뉴럴넷처럼 특정 방법론에 한정되지 않고 어느 정도 일반적인 방법론을 두루 다루면서도 최신성이 좋다는 점이 매력적이라 한번 정리해 보았습니다. 이 포스트를 통해, 최근 학계에서 주목받는 알고리즘들에 대한 개략적인 흐름을 살펴보고, 각 방법론이 유용한 데이터/비즈니스 상황에 대해 표로 정리해 보려고 합니다.  *이는 개인적인 관찰과 의견에 기반한 내용으로, 이 글을 읽으시는 분들의 조언과 지적이 필요합니다.*  


이 논문에서는 크게 3가지의 접근법으로 나누어 딥러닝 기반 추천 알고리즘을 나누고 있습니다.  
1) **Collaborative Filtering**
2) **Contents Based**
3) **Temporal/Sequential**  

이 외에도 여기서 제시하는 Taxonomy에서는 다뤄지지 않거나 별도로 분리되지 않는 [Context-aware](https://ieeexplore.ieee.org/abstract/document/7374144), [강화학습 기반](https://arxiv.org/abs/2109.10665), [Conversational Recommender Systems(CRS)](https://arxiv.org/abs/2004.00646), [Multi-armed Bandit](https://arxiv.org/abs/1904.10040) 등 다양한 추천의 갈래가 존재합니다. 각각의 주제에 대해 다루는 서베이 페이퍼가 공개되어 있으니 관심있는 독자 분들은 참고하셔도 좋을 것 같습니다.  

덧붙여, 방법론의 별칭 옆에 노란색 작은 숫자 ex) SVD++<font size="1"> <span style="color:orange">[3881]</span></font>는 글을 작성하는 당시까지의 피인용수를 적어두었습니다. 해당 논문이 얼마나 큰 관심을 받았는지 참고하는 용도로 보아주세요.  





<br />


<a id="cf-models"></a>
## 2. Collaborative Filtering Models  

<center><img src="/assets/materials/recsys/neural_survey/cf_chart.png" align="center" alt="drawing" width="500"/></center>   

<font size="1.5"><center> *이는 개인적인 관찰과 의견에 기반한 내용으로, 이 글을 읽으시는 분들의 조언과 지적이 필요합니다!* </center>  </font>   
<br>

Collaborative Filtering (CF, 협업 필터링) 기반 모델의 아이디어는, 모든 유저의 협업적인(collaborative) 행동을 활용해,
타겟 유저의 행동을 예측하자는 것입니다. 직관적으로는, **“너랑 비슷한 걸 좋아하는 애들은 이걸 좋아했으니 너도 좋아하겠지”** 라는 가정으로 추천을 제공하는 접근법이라고 할 수 있습니다. 초기에는 유저/아이템 기준으로 행동의 유사도를 메모리 기반으로 직접 계산하는 방법론이 제안되었는데, 그 이후(대략 Netflix Prize에서 SVD 모델이 우승한 이후) Matrix Factorization 방법론이 각광받았습니다.  

해당 논문에서는 CF 기반 모델을 크게 2가지로 나누었습니다.
1) Representation Learning (표현 학습)
2) Interaction Modeling (상호작용 모델링)  



### 2.1 Representation Learning (표현 학습)
이 방법론은, 유저와 아이템을 각각 잘 표현하는 임베딩 행렬을 만들어 내는 접근법입니다. 유저와 아이템의 interaction 정보가 주어졌을 때, 이들을 one-hot이 아닌 dense한 representation으로 표현해 냄으로써 유사한 아이템과 유저를 찾아냄으로써 특정 유저가 좋아할만한 상품이나 컨텐츠를 추천해 줄 수 있겠죠.  


입력 데이터와 처리 방식에 따라, 3가지로 나눌 수 있습니다.
1) 과거 행동 기반 Attention Aggregation model
2) 오토인코더 기반 모델
3) 그래프 학습 방법론

<br>

<center><img src="/assets/materials/recsys/neural_survey/cf_rep_summary.png" align="center" alt="drawing" width="500"/></center>   

<font size="2"><center> CF 기반 방법론의 representation learning 접근법 요약 </center>  </font>   
<br>

#### 2.1.1 과거 행동 기반 Attention Aggregation Models  

과거의 one-hot 유저 ID와 아이템 ID를 받는 고전적인 latent factor model들은 각각의 유저와 아이템을 자유 임베딩(free embedding)에 맵핑시켰습니다. 이런 방법 대신에, 더 나은 유저 representation 모델링을 위해 유저의 과거 행동 기록을 사용하는 것이 제안되었는데요.
- FISM<font size="1"> <span style="color:orange">[471]</span></font>, SVD++<font size="1"> <span style="color:orange">[3881]</span></font> …

<br>

<font size="2"> <span style="color:grey">
참고: SVD와 SVD++의 차이
요컨대, 구매 행위에서 드러나는 암묵적인 선호를 반영하도록 모델링했다는 내용입니다.
https://www.quora.com/Whats-the-difference-between-SVD-and-SVD++
The way to interpret this is that it is including the effect of the "implicit" information as opposed to p(u) that only includes the effect of the explicit one.
The way to interpret this is by understanding that the fact that a user rates an item is in itself an indication of preference.
In other words, chances that the user "likes" an item she has rated are higher than for a random not-rated item.
</span></font>


<br/>


그런데 유저의 선호를 모델링함에 있어 각 과거 아이템은 다른 기여도를 가질 것이라는 지적이 제기되었습니다. 이러한 문제를 해결하기 위해, Attention Mechanism을 결합한 방법론이 다수 제시 되었습니다.
- ACF(Attentive Collaborative Filtering)<font size="1"> <span style="color:orange">[18]</span></font>, NAIS(Neural Attentive Item Similarity model)<font size="1"> <span style="color:orange">[259]</span></font>, DeepICF(Deep Item-based CF)<font size="1"> <span style="color:orange">[124]</span></font>, DIN(Deep Interest Network)<font size="1"> <span style="color:orange">[621]</span></font> 등  


<center><img src="/assets/materials/recsys/neural_survey/cf_rep_att.png" align="center" alt="drawing" width="500"/></center>   

<font size="2"><center> Attention Aggregation 기반 representation learning 접근법 요약 </center>  </font>   
<br>


#### 2.1.2 오토인코더(AutoEncoder, AE) 기반 표현 학습

오토인코더는 입력을 재복원하여 출력을 입력과 동일하게 만들어내도록 하는, 마치 장구의 모양을 띠는 네트워크를 말합니다.  


<center><img src="/assets/materials/recsys/neural_survey/autoencoder.png" align="center" alt="drawing" width="500"/></center>   

<font size="2"><center> 출처: A Better Autoencoder for Image: Convolutional Autoencoder (Yifei Zhang, 2018) </center>  </font>   


크게 인코더와 디코더로 나뉘어져 있는 이 네트워크는, 두 파트 사이의 병목 부분에서 입력 데이터의 잠재된 표현(latent representation)을 학습하게 됩니다. 입력된 정보를 잘 압축하는 역할을 하는 부분이 인코더이고, 이를 잘 풀어내어 원래의 형상으로 만드는 것이 디코더의 역할입니다. 데이터를 압축하여 데이터 샘플 간의 의미적인 정보를 잘 보존하는 잠재 표현을 만들어 내는데, 이를 활용해 가까운 유저와 아이템 사이의 관계를 잘 학습하여 추천에 활용하겠다는 것이 오토인코더 기반 표현학습의 전략입니다. 달리 말해, 유저와 아이템 사이의 의미적인 관계를 잘 보존하는 매니폴드를 학습한다고도 할 수 있겠습니다.  

오토인코더 기반 모델은 불완전한 user-item matrix를 입력으로 받아, 인코더로 각 인스턴스의 잠재 표현을 학습합니다. 반대로 디코더 파트에서는 잠재 표현을 기반으로 입력 값을 재복원하는 구조를 띠고 있습니다. 비슷한 접근을 취하는 방법론으로는, 딥러닝이 아닌 선형적인 모델을 사용하는 Matrix Factorization 류의 알고리즘을 들 수 있습니다.  

본 논문에서 AE 기반 모델을 두가지 카테고리로 분류하고 있습니다.  
1) 오토인코더 변형 모델 (DAE, VAE): 유저 혹은 아이템 인코더를 학습하는 딥러닝 기법
2) 오토인코더의 유저/아이템의 이중성을 활용: 아이템과 유저 표현을 학습하는 두 병렬 인코더를 놓은 뒤, 아이템에 대한 유저의 선호를 모델링하기 위해 내적을 사용합니다.  


<center><img src="/assets/materials/recsys/neural_survey/autoencoder_models.png" align="center" alt="drawing" width="500"/></center>   

<font size="2"><center> 오토인코더 기반 표현 학습 알고리즘들 </center>  </font>   


#### 그래프 기반 표현 학습   


그래프 뉴럴넷(GNN)의 발전에 따라, 네트워크 내에서 한 개체가 갖는 관계적인 의미를 반영하여 추천에 활용하려는 움직임이 계속되고 있습니다. 여기서 살펴볼 방법론들은 그래프 구조를 활용해 추천에 적용하는 알고리즘들입니다.  

유저-아이템 인터렉션 그래프의 관점에서, 개별 인터렉션(구매, 조회..) 기록은 해당 유저의 1계 연결(first-order connectivity)으로 볼 수 있습니다. 이를 자연스럽게 확장해보면, 고계 연결성(high-order connectivity)을 user-item 그래프 구조에서 찾는 방법을 생각해볼 수 있을 텐데요. 가령 2계 연결(second-order connectivity)은 같은 아이템을 똑같이 상호작용한 비슷한 유저로 구성되어 있을 것입니다. GNN이 커뮤니티 내에서 그래프 구조를 모델링하는데 성공함에 따라, 유저-아이템 bipartite 그래프 구조를 모델링하는 연구가 진행되고 있습니다. 아래는 bipartite graph의 예시입니다.  


<center><img src="/assets/materials/recsys/neural_survey/bipartite.png" align="center" alt="drawing" width="500"/></center>   

<font size="2"><center> bipartite graph의 예시 </center>  </font>   




대부분 알고리즘의 작동 방식은, 유저-아이템 bipartite 그래프가 주어졌을 때 propagation을 통해 반복적으로 이웃의 정보를 교환함으로써 최종 아이템/유저 임베딩을 생성해내고, 이를 기반으로 유사도를 계산하여 추천을 제공하는 메커니즘을 따릅니다.  


<center><img src="/assets/materials/recsys/neural_survey/gnn_based.png" align="center" alt="drawing" width="500"/></center>   

<font size="2"><center> bipartite graph의 예시 </center>  </font>   




----------------


**개선을 위한 여러분의 피드백과 제안을 코멘트로 공유해 주세요.**
**내용에 대한 지적, 혹은 질문을 환영합니다.**  


**출처**  
