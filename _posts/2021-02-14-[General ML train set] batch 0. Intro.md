---
title: "[General ML Train set] batch 0. 인트로"
categories:
  - General Machine Learning
tags:
  - Introduction
---

> 일반적인 Machine Learning의 개념들을 하나씩 정리하는 시리즈입니다.


해당 포스트는 카이스트 문일철 교수님의 동의를 얻고, 강좌 내용과 자료, 그리고 reference의 자료를 참고하여 작성되었습니다. 원 강좌는 [여기](https://www.youtube.com/playlist?list=PLbhbGI_ppZISMV4tAWHlytBqNq1-lb8bz)에서 보실 수 있습니다.


### 들어가며

안녕하세요, 배우는 기계 러닝머신입니다! :man_technologist:  

기계학습에 대한 전반적인 개념을 구체적인 수학적 원리와 함께 정리하고자, 머신러닝 관련 시리즈를 연재할 계획인데요.

다음과 같은 점에 최대한 초점을 맞추어 작성하려고 합니다.

>  **1. 서두에 포스트를 요약하는 내용을 압축하여 전달한다**
>
>  **2. 가능한 한 쉽고 직관적인 예시를 들어 설명한다**
>
>  **3. 수학적인 보충 설명을 덧붙인다. 이는 설명의 직관성을 추구하기 위함이다.**

수학적인 설명은 공식의 유도, 수치적 계산 그 자체보다는 수식이 도입된 배경과 그 수식으로써 표현하고자 하는 알고리즘의 핵심적인 의미를 전달하기 위해서 소개할 예정입니다. 만일 아이디어가 전달 되기만 한다면 수식적인 설명은 다소 생략될수도 있고, 추가될 수도 있겠습니다.
<br/>

----

#### Contents
<br/>

목차는 문일철 교수님의 강좌 커리큘럼을 큰 틀로 가져갑니다.

<br/>

1.	[확률 통계와 기초](#nlp-and-graph)
2.	[기초 머신러닝](#creating-graph)
3.  [나이브 베이즈 분류기](#generating-sequences)
4.	[로지스틱 회귀](#implementation-3)
5.	[학습, 검증과 정규화](#implementation-4)
6.	[베이지안 네트워크](#implementation-5)
7.	[K-means 클러스터링과 Gaussian Mixture Model](#implementation-6)
8.	[히든 마코프 모델](#implementation-7)
9.	[Sampling Based Inference](#conclusion)

<br />

<a id="motivation"></a>
### Motivation  

이대로 첫 포스트를 끝내기는 아쉬우니, 기계학습을 배울 Motivation을 살펴 보고자 합니다.  

최근 인공지능, 지식 발견, 데이터 마이닝 등의 키워드가 떠오르고 있습니다. 기존의 패러다임으로는 해결할 수 없던 문제들을 다양한 데이터로부터 패턴을 찾아내어 해결할 수 있다는 메시지는 데이터의 범람과 컴퓨팅 기술의 발달, 알고리즘의 혁신 등으로 구체화되었고, 그 결과 실제 문제를 해결해 나가는 데 인공지능이 활용되기에 이르고 있습니다.  

그 사례는 매우 다양합니다. 제가 재직중인 기업에서 컨설팅한 기업의 산업군만 살펴 보아도 금융, 마케팅, 제조업, 서비스업, 유통업 등 산업을 가리지 않았고, 해결하는 데 활용하고자 했던 데이터 역시 고객 정보, 로그 데이터, 시계열, 이미지, 동영상, 텍스트 등 정형과 비정형을 넘나들고 때로는 다양한 형태의 데이터를 동시에 활용하기도 합니다.  

텍스트 분류, 추천 시스템, 이미지 인식, 이미지 생성, 음성 복제, 출하량 예측, 구매 예측, 이탈 예측 등의 많은 task가 목적이었으며 이 task의 종류 역시 시간이 흐를수록 대중화되는 기술이 다양해짐에 따라 늘어나고 있습니다.  


#### 머신러닝의 구분

크게 지도학습(Supervised Learning), 비지도학습(Unsupervised Learning), 강화학습(Reinforcement Learning)으로 나뉩니다. 이 시리즈에서는 지도/비지도 학습에 대해서만 다룰 예정입니다.

1) 지도학습 (Supervised Learning)
지도학습은 사람이 지정해주거나, 이미 레이블이 있어서 supervision, 즉 감독이 가능한 경우를 말합니다. 분류/회귀 문제를 들 수 있습니다.  

2) 비지도학습 (Unsupervised Learning)
비지도학습이란 있는 데이터를 그대로 감독 없이 분석하고자 할 때 사용됩니다.
군집화 등의 문제를 해결할 때 사용합니다. latent representation, 즉 어떠한 현상이 나타나는 잠재적인 요인을 표현하는 데 사용하기도 합니다.


----------------

<a id="conclusion"></a>
### 닫으며  

이 포스트 시리즈가, 다양한 머신러닝의 기초적이고 핵심적인 개념을 필요할 때 꺼내볼 수 있는 자료가 되었으면 좋겠습니다.

**개선을 위한 여러분의 피드백과 제안을 코멘트로 공유해 주세요.**
**내용에 대한 지적, 혹은 질문을 환영합니다.**  

**자료 공유를 허락해 주신 문일철 교수님께 감사의 말씀을 전합니다.**
